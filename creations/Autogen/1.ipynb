{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2daa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q autogenstudio --break-system-packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mvnucgnqoam",
   "metadata": {},
   "source": "# 🏗️ AutoGen Studio Installation\n\n<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 12px; color: white; margin: 20px 0;\">\n\n**This cell installs the AutoGen Studio package**, which provides a comprehensive framework for building multi-agent conversational systems. AutoGen Studio enables developers to create sophisticated AI agents that can collaborate, delegate tasks, and engage in complex workflows.\n\nThe `--break-system-packages` flag allows installation in system Python environments, though virtual environments are recommended for production. This package includes both high-level APIs for quick development and low-level components for custom agent architectures.\n\n</div>\n\n## Key Components\n\n| Component | Description |\n|-----------|-------------|\n| 🏗️ **Framework** | Multi-agent systems foundation |\n| 🤖 **Agents** | Conversational AI capabilities |\n| 🔧 **Tools** | High & low level APIs |\n\n---\n\n### 🌟 **Installation Features**\n- ✅ **Complete Framework**: Full multi-agent system support\n- ✅ **API Flexibility**: Both high-level and low-level interfaces  \n- ✅ **Development Ready**: Includes all necessary dependencies\n- ✅ **Production Support**: Scalable architecture components"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fbb8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "icmelmmhbuo",
   "metadata": {},
   "source": "# 🔐 Environment Configuration\n\n<div style=\"background: linear-gradient(135deg, #48bb78 0%, #38a169 100%); padding: 20px; border-radius: 12px; color: white; margin: 20px 0;\">\n\n**Loads environment variables from a .env file** to securely manage API keys and other sensitive configuration data. The `load_dotenv(override=True)` function reads variables from the .env file and makes them available to the application through `os.environ`.\n\nThe override parameter ensures that values in the .env file take precedence over existing environment variables. This approach follows security best practices by keeping sensitive credentials separate from source code and preventing accidental exposure in version control.\n\n</div>\n\n## 🛡️ Security Benefits\n\n<div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n\n<div style=\"flex: 1; background: #f7fafc; padding: 15px; border-radius: 8px; border-left: 4px solid #48bb78;\">\n\n### Environment Isolation\n- 🔑 **Secure API keys** - No hardcoded credentials\n- 🔒 **Version control safe** - .env files excluded\n- 🌍 **Environment specific** - Dev/prod separation\n- ⚙️ **Runtime configuration** - Dynamic loading\n\n</div>\n\n</div>\n\n---\n\n### 📋 **Configuration Process**\n1. **Load Environment** → Read .env file variables\n2. **Override Settings** → Prioritize .env values  \n3. **Secure Storage** → Keep credentials isolated\n4. **Runtime Access** → Available via `os.environ`"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03a4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9m9fwx4o4v",
   "metadata": {},
   "source": "# 🧠 Model Client Initialization\n\n<div style=\"background: linear-gradient(135deg, #3182ce 0%, #2c5282 100%); padding: 20px; border-radius: 12px; color: white; margin: 20px 0;\">\n\n**Creates an OpenAI chat completion client** configured to use the GPT-4 mini model for agent interactions. This client serves as the bridge between AutoGen agents and OpenAI's language models, handling API communication and response processing.\n\nGPT-4 mini is chosen for its balance of performance and cost-effectiveness, making it suitable for conversational agents and tool usage scenarios. The client automatically manages authentication using API keys from environment variables and provides consistent interfaces for model interactions.\n\n</div>\n\n## ⚡ Client Architecture\n\n```mermaid\ngraph LR\n    A[🔑 Environment] --> B[🔧 OpenAI Client]\n    B --> C[🧠 GPT-4 Mini]\n    C --> D[💬 Agent Response]\n```\n\n<div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;\">\n\n<div style=\"background: #ebf8ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3182ce;\">\n\n### 🤖 **GPT-4 Mini Features**\n- **Performance**: Optimized for conversational AI\n- **Cost-effective**: Balanced pricing model  \n- **Tool support**: Function calling capabilities\n- **Context**: Large context window\n\n</div>\n\n<div style=\"background: #f0fff4; padding: 15px; border-radius: 8px; border-left: 4px solid #38a169;\">\n\n### 🔗 **Auto Authentication**\n- **Environment**: Reads API keys securely\n- **Automatic**: No manual key management\n- **Consistent**: Unified interface design\n- **Reliable**: Built-in error handling\n\n</div>\n\n</div>\n\n---\n\n### 🔄 **Processing Flow**\n**Environment Variables** → **Client Configuration** → **Model Connection** → **Response Generation**"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed566939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextMessage(source='user', models_usage=None, metadata={}, content=\"I'd like to go to London\", type='TextMessage')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "message = TextMessage(content=\"I'd like to go to London\", source=\"user\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84rm807hwj",
   "metadata": {},
   "source": "# 💬 Creating a Text Message\n\n<div style=\"background: linear-gradient(135deg, #805ad5 0%, #6b46c1 100%); padding: 20px; border-radius: 12px; color: white; margin: 20px 0;\">\n\n**Demonstrates creating a TextMessage object** that represents user input in the conversational flow between humans and agents. TextMessage is a core data structure in AutoGen that encapsulates message content, source attribution, and metadata for tracking conversations.\n\nThe source parameter identifies the message origin (user, agent, or system), enabling proper conversation flow management and response routing. This standardized format ensures compatibility across different agent types and facilitates complex multi-agent interactions.\n\n</div>\n\n## 📋 Message Structure\n\n<div style=\"display: grid; grid-template-columns: 2fr 1fr; gap: 20px; margin: 20px 0;\">\n\n<div style=\"background: #faf5ff; padding: 15px; border-radius: 8px; border-left: 4px solid #805ad5;\">\n\n### Core Components\n- **📝 Content**: The actual message text content\n- **🏷️ Source**: Origin identification (user/agent/system)  \n- **📊 Metadata**: Additional tracking information\n- **🔗 Type**: Message classification for routing\n\n### Compatibility Features\n- ✅ **Cross-agent**: Works with all AutoGen agent types\n- ✅ **Multi-agent**: Supports complex conversation flows\n- ✅ **Standardized**: Consistent format across systems\n- ✅ **Extensible**: Can add custom metadata fields\n\n</div>\n\n<div style=\"background: #f7fafc; padding: 15px; border-radius: 8px; text-align: center;\">\n\n### 💬 TextMessage\n**Universal Format**\n\n```python\nTextMessage(\n  content=\"I'd like to go to London\",\n  source=\"user\"\n)\n```\n\n<span style=\"background: #e6fffa; color: #38a169; padding: 4px 8px; border-radius: 12px; font-size: 12px;\">✅ Valid</span>\n\n</div>\n\n</div>\n\n---\n\n### 🔄 **Message Lifecycle**\n**User Input** → **TextMessage Creation** → **Agent Processing** → **Response Generation**"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7193e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers.\",\n",
    "    model_client_stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86froreij2m",
   "metadata": {},
   "source": "# 🤖 Basic Assistant Agent\n\n<div style=\"background: linear-gradient(135deg, #ed8936 0%, #dd6b20 100%); padding: 20px; border-radius: 12px; color: white; margin: 20px 0;\">\n\n**Creates a simple assistant agent** with a custom system message for airline-related interactions and streaming capabilities enabled. The system message defines the agent's personality, role, and behavioral guidelines, instructing it to provide short, humorous responses in an airline context.\n\nStreaming is enabled through `model_client_stream=True`, allowing for real-time response generation and improved user experience during longer conversations. This demonstrates the fundamental AutoGen agent pattern: combining a language model client with specific instructions and configuration.\n\n</div>\n\n## 🛠️ Agent Configuration\n\n<div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;\">\n\n<div style=\"background: #fffaf0; padding: 15px; border-radius: 8px; border-left: 4px solid #ed8936;\">\n\n### Core Components\n- **📋 System Message**: Defines personality and behavior\n- **🔧 Model Client**: GPT-4 mini integration  \n- **⚡ Streaming**: Real-time response generation\n- **🎭 Personality**: Humorous airline assistant\n\n</div>\n\n<div style=\"background: #f0fff4; padding: 15px; border-radius: 8px; border-left: 4px solid #38a169;\">\n\n### ✈️ Airline Context\n*\"You are a helpful assistant for an airline. You give short, humorous answers.\"*\n\n**Traits:**\n- 😄 **Humorous**: Witty responses  \n- 📏 **Concise**: Short answers\n- ✈️ **Airline-focused**: Domain expertise\n- 🎯 **Helpful**: Customer service oriented\n\n</div>\n\n</div>\n\n## 🏗️ Agent Architecture\n\n```\nSystem Message + Model Client + Configuration = 🤖 Agent Instance\n```\n\n---\n\n### ⚡ **Key Benefits**\n- **🎭 Personality**: Custom behavioral guidelines\n- **⚡ Streaming**: Real-time response generation  \n- **🔧 Flexibility**: Configurable system messages\n- **📱 Responsive**: Improved user experience"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9740cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! London: where the rain is as reliable as the Tube delays! When do you want to fly?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "response = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jjjqs5s3s5b",
   "metadata": {},
   "source": "## Agent Message Processing\nSends a message to the agent asynchronously and retrieves the response using a cancellation token for execution control.\nThe `on_messages` method processes the input message through the agent's language model and system instructions to generate contextually appropriate responses.\nCancellationToken provides a mechanism to interrupt long-running operations, ensuring responsive applications and proper resource management.\nThis asynchronous pattern allows for non-blocking agent interactions, enabling concurrent processing of multiple conversations or integration with web frameworks.\n\n```mermaid\ngraph LR\n    A[User Message] --> B[Agent.on_messages]\n    C[CancellationToken] --> B\n    B --> D[Language Model Processing]\n    D --> E[System Message Application]\n    E --> F[Response Generation]\n    F --> G[Chat Message Content]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d047bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Delete existing database file if it exists\n",
    "if os.path.exists(\"tickets.db\"):\n",
    "    os.remove(\"tickets.db\")\n",
    "\n",
    "# Create the database and the table\n",
    "conn = sqlite3.connect(\"tickets.db\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"CREATE TABLE cities (city_name TEXT PRIMARY KEY, round_trip_price REAL)\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b3jw7mdl",
   "metadata": {},
   "source": "## Database Initialization\nSets up a SQLite database with a cities table to store flight pricing information for different destinations.\nThe database schema includes city_name as the primary key and round_trip_price as a real number, creating a simple but effective data store for airline pricing.\nSQLite is chosen for its simplicity and file-based storage, making it ideal for demonstrations and development environments without requiring external database servers.\nThis step establishes the foundation for tool-enhanced agents that can query real data, demonstrating how AI agents can interact with structured data sources.\n\n```mermaid\ngraph TD\n    A[Check Existing DB] --> B{Database Exists?}\n    B -->|Yes| C[Delete tickets.db]\n    B -->|No| D[Create New Connection]\n    C --> D\n    D --> E[Create Cities Table]\n    E --> F[Define Schema: city_name, price]\n    F --> G[Commit & Close]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e902dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate our database\n",
    "def save_city_price(city_name, round_trip_price):\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"REPLACE INTO cities (city_name, round_trip_price) VALUES (?, ?)\", (city_name.lower(), round_trip_price))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Some cities!\n",
    "save_city_price(\"London\", 299)\n",
    "save_city_price(\"Paris\", 399)\n",
    "save_city_price(\"Rome\", 499)\n",
    "save_city_price(\"Madrid\", 550)\n",
    "save_city_price(\"Barcelona\", 580)\n",
    "save_city_price(\"Berlin\", 525)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pme6c2vr84",
   "metadata": {},
   "source": "## Database Population\nDefines a function to insert city prices and populates the database with sample roundtrip ticket prices for major European destinations.\nThe `save_city_price` function uses REPLACE INTO SQL command, which handles both insertions and updates, ensuring data consistency when prices change.\nCity names are automatically converted to lowercase for consistent querying and comparison, preventing case-sensitivity issues in lookups.\nThe sample data includes popular European destinations with realistic price ranges, providing a meaningful dataset for agent tool demonstrations and user interactions."
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486d0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get price for a city\n",
    "def get_city_price(city_name: str) -> float | None:\n",
    "    \"\"\" Get the roundtrip ticket price to travel to the city \"\"\"\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT round_trip_price FROM cities WHERE city_name = ?\", (city_name.lower(),))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    return result[0] if result else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ane1ju4fc8",
   "metadata": {},
   "source": "## Price Retrieval Function\nCreates a function that queries the database to fetch roundtrip ticket prices for specified cities with proper error handling.\nThe function implements case-insensitive city name matching by converting input to lowercase, ensuring consistent lookups regardless of user input formatting.\nReturn value handling includes a None check to gracefully handle requests for cities not in the database, preventing runtime errors in agent interactions.\nThis function serves as a tool that AutoGen agents can use to access real pricing data, demonstrating the integration of AI agents with external data sources.\n\n```mermaid\ngraph TD\n    A[City Name Input] --> B[Convert to Lowercase]\n    B --> C[Database Connection]\n    C --> D[Execute SELECT Query]\n    D --> E{Result Found?}\n    E -->|Yes| F[Return Price]\n    E -->|No| G[Return None]\n    F --> H[Close Connection]\n    G --> H\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a8adba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_city_price(\"Rome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gcza07qbhg5",
   "metadata": {},
   "source": "## Function Testing\nTests the price retrieval function by fetching the roundtrip price for Rome, validating both function implementation and database connectivity.\nThis verification step ensures the function correctly queries the database and returns the expected price value (499.0 for Rome).\nTesting individual components before integration is a crucial development practice that helps identify issues early in the development process.\nThe successful test confirms that the tool is ready for integration with AutoGen agents, providing confidence in the data layer functionality."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170437be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "smart_agent = AssistantAgent(\n",
    "    name=\"smart_airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers, including the price of a roundtrip ticket.\",\n",
    "    model_client_stream=True,\n",
    "    tools=[get_city_price],\n",
    "    reflect_on_tool_use=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zq2574erok",
   "metadata": {},
   "source": "## Tool-Enhanced Agent\nCreates an advanced assistant agent with tool capabilities to query prices and reflection features for improved response accuracy.\nThe tools parameter integrates the `get_city_price` function, enabling the agent to access real pricing data during conversations and provide accurate information.\n`reflect_on_tool_use=True` activates the agent's ability to analyze and validate its tool usage, leading to more reliable and contextually appropriate responses.\nThis demonstrates AutoGen's powerful tool integration capabilities, showing how agents can seamlessly combine language understanding with external data access and function execution.\n\n```mermaid\ngraph TD\n    A[User Query] --> B[Smart Agent]\n    B --> C{Need Price Data?}\n    C -->|Yes| D[Call get_city_price Tool]\n    C -->|No| E[Generate Response]\n    D --> F[Database Query]\n    F --> G[Price Retrieved]\n    G --> H[Reflection on Tool Use]\n    H --> I[Enhanced Response with Price]\n    E --> J[Regular Response]\n    I --> K[Final Answer]\n    J --> K\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cb3ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_OpQPhbbvSddcMoOenY5orE5K', arguments='{\"city_name\":\"London\"}', name='get_city_price')]\n",
      "[FunctionExecutionResult(content='299.0', name='get_city_price', call_id='call_OpQPhbbvSddcMoOenY5orE5K', is_error=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A trip to London? Brilliant choice! A roundtrip ticket will set you back about $299. Just remember, the only \"fish and chips\" policy we abide by is consuming them, not taking them as carry-ons! ✈️🍟'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await smart_agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "for inner_message in response.inner_messages:\n",
    "    print(inner_message.content)\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mk0j3l39pd",
   "metadata": {},
   "source": "## Tool-Enabled Response\nDemonstrates the agent using the price retrieval tool to provide accurate pricing information in its response, showcasing the complete tool integration workflow.\nThe inner_messages output reveals the agent's internal process: first making a function call to get_city_price(\"London\"), then receiving the execution result (299.0).\nThis transparency in agent reasoning helps developers understand how tools are being used and debug any issues in the integration process.\nThe final response combines the retrieved pricing data with the agent's humorous personality, showing how tool-enhanced agents maintain their character while providing factual information.\n\n```mermaid\ngraph LR\n    A[User: \"I'd like to go to London\"] --> B[Agent Processing]\n    B --> C[Function Call: get_city_price(\"London\")]\n    C --> D[Database Returns: 299.0]\n    D --> E[Function Result Processing]\n    E --> F[Response Generation with Price]\n    F --> G[\"Response: $299 + Humor\"]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f666bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}