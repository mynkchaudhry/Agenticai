{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2daa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q autogenstudio --break-system-packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mvnucgnqoam",
   "metadata": {},
   "source": "## AutoGen Studio Installation\n\nThis cell installs the AutoGen Studio package, which is a comprehensive framework designed for building multi-agent conversational systems. AutoGen Studio provides developers with the tools needed to create sophisticated AI agents that can work together, share tasks, and handle complex workflows.\n\nThe installation uses the pip package manager with specific flags. The `--break-system-packages` flag allows installation in system Python environments, though using virtual environments is recommended for production applications. This package includes both high-level APIs for quick development and low-level components for building custom agent architectures.\n\nKey features of AutoGen Studio include:\n- Multi-agent system support for collaborative AI workflows\n- Conversational AI capabilities for natural language interactions\n- Both high-level and low-level APIs for different development needs\n- Production-ready components for scalable deployments\n- Complete framework with all necessary dependencies included\n\nThe installation process downloads and installs all required dependencies, making the system ready for immediate use in developing multi-agent applications."
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fbb8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "icmelmmhbuo",
   "metadata": {},
   "source": "## Environment Configuration\n\nThis cell loads environment variables from a .env file to securely manage API keys and other sensitive configuration data. The `load_dotenv()` function is a standard way to handle environment variables in Python applications, ensuring that sensitive information like API keys are kept separate from the source code.\n\nThe function `load_dotenv(override=True)` performs several important tasks:\n- Reads variables from a .env file in the project directory\n- Makes these variables available to the application through `os.environ`\n- The `override=True` parameter ensures that values in the .env file take precedence over existing environment variables\n- Returns `True` when the .env file is successfully loaded\n\nThis approach follows security best practices by:\n- Keeping sensitive credentials separate from source code\n- Preventing accidental exposure of API keys in version control systems\n- Allowing different configurations for development, testing, and production environments\n- Providing a standardized way to manage application configuration\n\nThe .env file typically contains entries like `OPENAI_API_KEY=your_api_key_here`, which can then be accessed in the code using `os.environ.get('OPENAI_API_KEY')`. This pattern is widely used in professional software development for secure credential management."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03a4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9m9fwx4o4v",
   "metadata": {},
   "source": "## Model Client Initialization\n\nThis cell creates an OpenAI chat completion client that is configured to use the GPT-4 mini model for agent interactions. The client serves as a bridge between AutoGen agents and OpenAI's language models, handling all API communication and response processing automatically.\n\nThe `OpenAIChatCompletionClient` is initialized with the following characteristics:\n- Uses the \"gpt-4o-mini\" model, which provides a good balance of performance and cost-effectiveness\n- Automatically manages authentication using API keys from environment variables\n- Handles all the technical details of communicating with OpenAI's servers\n- Provides a consistent interface for AutoGen agents to interact with the language model\n\nGPT-4 mini was chosen for this example because:\n- It offers excellent performance for conversational agents and tool usage scenarios\n- It has a lower cost compared to the full GPT-4 model while maintaining high quality\n- It supports function calling, which is essential for tool-enhanced agents\n- It has a large context window for handling longer conversations\n\nThe client automatically reads the API key from environment variables (typically `OPENAI_API_KEY`) that were loaded in the previous cell. This design ensures secure authentication without hardcoding sensitive information in the source code.\n\nOnce created, this client can be used by multiple agents throughout the application, providing a centralized way to manage model interactions and configuration."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed566939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextMessage(source='user', models_usage=None, metadata={}, content=\"I'd like to go to London\", type='TextMessage')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "message = TextMessage(content=\"I'd like to go to London\", source=\"user\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84rm807hwj",
   "metadata": {},
   "source": "## Creating a Text Message\n\nThis cell demonstrates how to create a TextMessage object, which is a fundamental data structure in AutoGen that represents user input in conversations between humans and AI agents. The TextMessage class encapsulates all the information needed for proper message handling and routing within the AutoGen system.\n\nThe TextMessage object contains several important components:\n- **Content**: The actual text of the message (\"I'd like to go to London\" in this example)\n- **Source**: Identifies who sent the message (in this case \"user\")\n- **Type**: Automatically set to \"TextMessage\" for proper routing\n- **Metadata**: Additional information that can be used for tracking and processing\n\nThe source parameter is particularly important because it tells the system who originated the message. Common source values include:\n- \"user\" for messages from human users\n- \"assistant\" or agent names for messages from AI agents\n- \"system\" for internal system messages\n\nThis standardized message format ensures compatibility across different types of AutoGen agents and facilitates complex multi-agent interactions. The consistent structure allows agents to:\n- Properly route messages to the intended recipients\n- Maintain conversation history and context\n- Handle different types of content appropriately\n- Support features like conversation branching and message filtering\n\nWhen you run this cell, it creates the TextMessage object and displays its complete structure, showing all the fields and their values. This helps you understand exactly what information is being passed between agents in the system."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7193e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers.\",\n",
    "    model_client_stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86froreij2m",
   "metadata": {},
   "source": "## Basic Assistant Agent\n\nThis cell creates a simple assistant agent with custom personality traits and streaming capabilities. The AssistantAgent is one of the most commonly used agent types in AutoGen, designed to handle conversational interactions with users while maintaining specific behavioral characteristics defined by the system message.\n\nThe agent is configured with several key parameters:\n- **Name**: \"airline_agent\" - This identifier helps distinguish this agent from others in multi-agent scenarios\n- **Model Client**: Uses the OpenAI client created in the previous cell for language model access\n- **System Message**: Defines the agent's personality as a helpful airline assistant that gives short, humorous answers\n- **Streaming**: Enabled with `model_client_stream=True` for real-time response generation\n\nThe system message is crucial because it shapes how the agent behaves and responds. In this case, the agent is instructed to:\n- Act as a helpful assistant specifically for an airline company\n- Provide short responses rather than lengthy explanations\n- Include humor in its responses to make interactions more engaging\n- Focus on airline-related topics and customer service scenarios\n\nStreaming is enabled to improve user experience by allowing responses to be generated and displayed in real-time rather than waiting for the complete response. This is particularly useful for longer responses or when using the agent in interactive applications.\n\nThe agent combines three essential components: a language model (through the model client), specific instructions (through the system message), and configuration settings (like streaming). This pattern demonstrates the fundamental AutoGen approach of creating specialized agents by combining these elements in different ways.\n\nOnce created, this agent can process messages, generate responses, and maintain conversations while staying true to its defined personality and role as an airline customer service assistant."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9740cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! London: where the rain is as reliable as the Tube delays! When do you want to fly?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "response = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jjjqs5s3s5b",
   "metadata": {},
   "source": "## Agent Message Processing\n\nThis cell demonstrates how to send a message to an agent and receive a response using AutoGen's asynchronous message processing system. The `on_messages` method is the primary way to interact with agents, allowing you to send one or more messages and get the agent's response.\n\nThe code performs several important operations:\n- **Message Processing**: The agent receives the TextMessage created in the previous cell\n- **Asynchronous Execution**: Uses `await` to handle the agent's response without blocking the program\n- **Cancellation Token**: Provides a mechanism to interrupt long-running operations if needed\n- **Response Extraction**: Retrieves the actual response content from the agent's reply\n\nThe `CancellationToken()` is a safety feature that allows you to cancel the operation if it takes too long or if you need to stop it for any reason. This is particularly useful in production applications where you want to prevent operations from running indefinitely.\n\nWhen the agent processes the message, it:\n1. Receives the user's message about wanting to go to London\n2. Applies its system message instructions (being helpful and humorous about airline topics)\n3. Generates an appropriate response using the GPT-4 mini model\n4. Returns the response in a structured format\n\nThe response object contains multiple pieces of information:\n- **chat_message.content**: The actual text response from the agent\n- **models_usage**: Information about token usage and API costs (if available)\n- **metadata**: Additional processing information\n\nThe final line `response.chat_message.content` extracts just the text content of the agent's response, which is typically what you want to display to users or use in your application. This pattern of sending messages and extracting responses is fundamental to building conversational applications with AutoGen."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d047bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Delete existing database file if it exists\n",
    "if os.path.exists(\"tickets.db\"):\n",
    "    os.remove(\"tickets.db\")\n",
    "\n",
    "# Create the database and the table\n",
    "conn = sqlite3.connect(\"tickets.db\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"CREATE TABLE cities (city_name TEXT PRIMARY KEY, round_trip_price REAL)\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b3jw7mdl",
   "metadata": {},
   "source": "## Database Initialization\n\nThis cell sets up a SQLite database to store flight pricing information for different destinations. SQLite is a lightweight, file-based database that is perfect for demonstrations and development environments because it doesn't require a separate database server to be running.\n\nThe code performs several database operations:\n- **File Management**: First checks if a database file named \"tickets.db\" already exists and removes it to start fresh\n- **Database Creation**: Creates a new SQLite database connection to a file called \"tickets.db\"\n- **Table Structure**: Creates a table named \"cities\" with two columns: city_name (text) and round_trip_price (real number)\n- **Primary Key**: Sets city_name as the primary key, ensuring each city appears only once in the database\n\nThe database schema is designed to be simple yet functional:\n- `city_name TEXT PRIMARY KEY`: Stores the name of the destination city and serves as the unique identifier\n- `round_trip_price REAL`: Stores the price of a round-trip ticket to that destination as a decimal number\n\nThis database will serve as a data source for the tool-enhanced agents that we'll create later in this notebook. By having real data stored in a database, we can demonstrate how AutoGen agents can interact with external data sources to provide accurate, up-to-date information to users.\n\nThe `conn.commit()` ensures that the table creation is permanently saved to the database file, and `conn.close()` properly closes the database connection to free up resources. This pattern of connecting, performing operations, committing changes, and closing the connection is a best practice for database operations."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e902dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate our database\n",
    "def save_city_price(city_name, round_trip_price):\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"REPLACE INTO cities (city_name, round_trip_price) VALUES (?, ?)\", (city_name.lower(), round_trip_price))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Some cities!\n",
    "save_city_price(\"London\", 299)\n",
    "save_city_price(\"Paris\", 399)\n",
    "save_city_price(\"Rome\", 499)\n",
    "save_city_price(\"Madrid\", 550)\n",
    "save_city_price(\"Barcelona\", 580)\n",
    "save_city_price(\"Berlin\", 525)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pme6c2vr84",
   "metadata": {},
   "source": "## Database Population\n\nThis cell defines a function to insert city prices into the database and then populates it with sample roundtrip ticket prices for several popular European destinations. The function provides a reusable way to add or update pricing information in the database.\n\nThe `save_city_price` function includes several important features:\n- **Parameters**: Takes two inputs - the city name as a string and the roundtrip price as a number\n- **Database Connection**: Opens a connection to the same \"tickets.db\" file created previously\n- **REPLACE Operation**: Uses `REPLACE INTO` SQL command, which either inserts a new record or updates an existing one\n- **Case Normalization**: Converts city names to lowercase using `city_name.lower()` to ensure consistent data storage and searching\n- **Safe Closure**: Always commits changes and closes the database connection properly\n\nThe sample data includes six major European destinations with realistic pricing:\n- London: $299 - Popular destination with competitive pricing\n- Paris: $399 - Slightly higher due to its status as a major tourist hub\n- Rome: $499 - Historic destination with moderate pricing\n- Madrid: $550 - Spanish capital with standard European pricing\n- Barcelona: $580 - Popular Mediterranean destination\n- Berlin: $525 - German capital with mid-range pricing\n\nThe use of `REPLACE INTO` instead of `INSERT INTO` is important because it handles both new entries and updates to existing prices without throwing errors. This makes the function robust and suitable for use in applications where prices might need to be updated regularly.\n\nThe lowercase conversion ensures that searches will work consistently regardless of how users type city names (e.g., \"london\", \"LONDON\", or \"London\" will all work the same way)."
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486d0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get price for a city\n",
    "def get_city_price(city_name: str) -> float | None:\n",
    "    \"\"\" Get the roundtrip ticket price to travel to the city \"\"\"\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT round_trip_price FROM cities WHERE city_name = ?\", (city_name.lower(),))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    return result[0] if result else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ane1ju4fc8",
   "metadata": {},
   "source": "## Price Retrieval Function\nCreates a function that queries the database to fetch roundtrip ticket prices for specified cities with proper error handling.\nThe function implements case-insensitive city name matching by converting input to lowercase, ensuring consistent lookups regardless of user input formatting.\nReturn value handling includes a None check to gracefully handle requests for cities not in the database, preventing runtime errors in agent interactions.\nThis function serves as a tool that AutoGen agents can use to access real pricing data, demonstrating the integration of AI agents with external data sources.\n\n```mermaid\ngraph TD\n    A[City Name Input] --> B[Convert to Lowercase]\n    B --> C[Database Connection]\n    C --> D[Execute SELECT Query]\n    D --> E{Result Found?}\n    E -->|Yes| F[Return Price]\n    E -->|No| G[Return None]\n    F --> H[Close Connection]\n    G --> H\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a8adba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_city_price(\"Rome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gcza07qbhg5",
   "metadata": {},
   "source": "## Function Testing\nTests the price retrieval function by fetching the roundtrip price for Rome, validating both function implementation and database connectivity.\nThis verification step ensures the function correctly queries the database and returns the expected price value (499.0 for Rome).\nTesting individual components before integration is a crucial development practice that helps identify issues early in the development process.\nThe successful test confirms that the tool is ready for integration with AutoGen agents, providing confidence in the data layer functionality."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170437be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "smart_agent = AssistantAgent(\n",
    "    name=\"smart_airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers, including the price of a roundtrip ticket.\",\n",
    "    model_client_stream=True,\n",
    "    tools=[get_city_price],\n",
    "    reflect_on_tool_use=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zq2574erok",
   "metadata": {},
   "source": "## Tool-Enhanced Agent\nCreates an advanced assistant agent with tool capabilities to query prices and reflection features for improved response accuracy.\nThe tools parameter integrates the `get_city_price` function, enabling the agent to access real pricing data during conversations and provide accurate information.\n`reflect_on_tool_use=True` activates the agent's ability to analyze and validate its tool usage, leading to more reliable and contextually appropriate responses.\nThis demonstrates AutoGen's powerful tool integration capabilities, showing how agents can seamlessly combine language understanding with external data access and function execution.\n\n```mermaid\ngraph TD\n    A[User Query] --> B[Smart Agent]\n    B --> C{Need Price Data?}\n    C -->|Yes| D[Call get_city_price Tool]\n    C -->|No| E[Generate Response]\n    D --> F[Database Query]\n    F --> G[Price Retrieved]\n    G --> H[Reflection on Tool Use]\n    H --> I[Enhanced Response with Price]\n    E --> J[Regular Response]\n    I --> K[Final Answer]\n    J --> K\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cb3ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_OpQPhbbvSddcMoOenY5orE5K', arguments='{\"city_name\":\"London\"}', name='get_city_price')]\n",
      "[FunctionExecutionResult(content='299.0', name='get_city_price', call_id='call_OpQPhbbvSddcMoOenY5orE5K', is_error=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A trip to London? Brilliant choice! A roundtrip ticket will set you back about $299. Just remember, the only \"fish and chips\" policy we abide by is consuming them, not taking them as carry-ons! ✈️🍟'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await smart_agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "for inner_message in response.inner_messages:\n",
    "    print(inner_message.content)\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mk0j3l39pd",
   "metadata": {},
   "source": "## Tool-Enabled Response\nDemonstrates the agent using the price retrieval tool to provide accurate pricing information in its response, showcasing the complete tool integration workflow.\nThe inner_messages output reveals the agent's internal process: first making a function call to get_city_price(\"London\"), then receiving the execution result (299.0).\nThis transparency in agent reasoning helps developers understand how tools are being used and debug any issues in the integration process.\nThe final response combines the retrieved pricing data with the agent's humorous personality, showing how tool-enhanced agents maintain their character while providing factual information.\n\n```mermaid\ngraph LR\n    A[User: \"I'd like to go to London\"] --> B[Agent Processing]\n    B --> C[Function Call: get_city_price(\"London\")]\n    C --> D[Database Returns: 299.0]\n    D --> E[Function Result Processing]\n    E --> F[Response Generation with Price]\n    F --> G[\"Response: $299 + Humor\"]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f666bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}