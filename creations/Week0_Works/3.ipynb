{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbb6bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pypdf gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3iufq7q0qd8",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Package Installation\n",
    "\n",
    "**Getting our digital toolbox ready for the AI construction project**\n",
    "\n",
    "*Note: The `--break-system-packages` flag is the equivalent of saying \"I know what I'm doing\" to your Python environment. Use wisely.*\n",
    "\n",
    "We're installing three essential packages:\n",
    "- **pypdf**: For extracting text from PDF documents (because copy-paste is so 2010)\n",
    "- **gradio**: For creating beautiful web interfaces without the CSS headaches  \n",
    "- **openai**: For communicating with our AI overlords\n",
    "\n",
    "The `-q` flag keeps the installation process quiet and professional, just like a good AI assistant should be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26kyksfkt4a",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%; border-collapse: collapse; text-align: left;\">\n",
    "  <tr>\n",
    "    <td style=\"width: 150px; text-align: center; vertical-align: middle;\">\n",
    "    <img src=\"../../assests/day.png\" alt=\"Here we go\" width=\"150\" height=\"150\" style=\"display: block; margin: auto;\" />\n",
    "    </td>\n",
    "    <td style=\"vertical-align: middle; padding-left: 15px;\">\n",
    "      <h2 style=\"color: #ff7800; margin: 0;\">Are you set for the challenge?</h2>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "# Personal AI Assistant with Quality Control System\n",
    "\n",
    "**Building a sophisticated chatbot that represents you professionally while maintaining quality standards**\n",
    "\n",
    "*Because sometimes even AI needs a supervisor to make sure it doesn't go rogue during job interviews.*\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook demonstrates the creation of a personal AI assistant that can represent an individual on their website or portfolio. The system includes:\n",
    "\n",
    "- **PDF-based knowledge extraction** from professional profiles\n",
    "- **Dynamic system prompt generation** for accurate representation  \n",
    "- **Interactive web interface** using Gradio\n",
    "- **Quality control evaluation system** with automatic response refinement\n",
    "- **Multi-model architecture** for enhanced reliability\n",
    "\n",
    "The result? An AI that knows you better than your mother and speaks more professionally than a corporate executive.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736011ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyfish/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cqgpo1kuy05",
   "metadata": {},
   "source": [
    "## Step 2: Import Essential Libraries\n",
    "\n",
    "**Assembling our arsenal of Python tools**\n",
    "\n",
    "*Pro tip: If you encounter any unfamiliar packages, ChatGPT is your best friend for explanations. It's like having a technical mentor who never gets tired of answering \"what does this do?\" questions.*\n",
    "\n",
    "Our imports include:\n",
    "- **dotenv**: For secure environment variable management\n",
    "- **openai**: OpenAI API client for LLM interactions\n",
    "- **pypdf**: PDF text extraction capabilities  \n",
    "- **gradio**: Web interface framework\n",
    "- **tqdm**: Progress bars for long-running operations (because waiting without feedback is torture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a71d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ougozetfu6",
   "metadata": {},
   "source": [
    "## Step 3: Initialize API Client\n",
    "\n",
    "**Connecting to the AI mothership**\n",
    "\n",
    "*The `override=True` parameter ensures we get the freshest environment variables, not the stale ones from three coffee breaks ago.*\n",
    "\n",
    "This step performs two crucial operations:\n",
    "1. **Load environment variables** from the .env file with override enabled\n",
    "2. **Initialize OpenAI client** using the loaded API key for seamless LLM communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b86e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mynkchaudhry/Agenticai/assests/Profile.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/mynkchaudhry/Agenticai/assests/Profile.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m linkedin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pypdf/_reader.py:131\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_id2num: Optional[\u001b[38;5;28mdict\u001b[39m[Any, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validated_root: Optional[DictionaryObject] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_objects: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pypdf/_reader.py:150\u001b[0m, in \u001b[0;36mPdfReader._initialize_stream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    151\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mynkchaudhry/Agenticai/assests/Profile.pdf'"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"/Users/mynkchaudhry/Agenticai/assests/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58o3lhiw9r",
   "metadata": {},
   "source": [
    "## Step 4: PDF Knowledge Extraction\n",
    "\n",
    "**Mining professional gold from PDF documents**\n",
    "\n",
    "*Think of this as digitally photocopying someone's entire professional life, but in a completely legal and ethical way.*\n",
    "\n",
    "This process extracts comprehensive professional information from a LinkedIn profile PDF:\n",
    "\n",
    "**Process Flow:**\n",
    "1. **Initialize PdfReader** with the target profile document\n",
    "2. **Iterate through all pages** to ensure complete data capture\n",
    "3. **Extract and concatenate text** from each page with safety checks\n",
    "4. **Compile complete profile** into a single searchable string\n",
    "\n",
    "The result is a complete digital representation of professional experience, skills, and background information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "mayanktalan98@gmail.com\n",
      "www.linkedin.com/in/\n",
      "mynkchaudhry (LinkedIn)\n",
      "Top Skills\n",
      "Chatbots\n",
      "Knowledge Engineering\n",
      "Retrieval-Augmented Generation\n",
      "(RAG)\n",
      "Certifications\n",
      "AI Agents Fundamentals\n",
      "BFF Hackathon\n",
      "Google Cloud\n",
      "Mayank Chaudhary\n",
      "AI Engineer @jellyfishtechnologies\n",
      "Noida, Uttar Pradesh, India\n",
      "Summary\n",
      "B.Tech student from St. Andrews Institute of Technology and\n",
      "Management, I am driven by an unwavering passion to learn\n",
      "and innovate in the realms of #AI and #ML, encompassing\n",
      "#DeepLearning, #ComputerVision, #Chatbots, #GenerativeAI, and\n",
      "machine learning algorithms.\n",
      "The #techstack I am well-versed with includes #LLMs, #RAG,\n",
      "#HuggingFace, #Computervision, #NLP, #Python, and #SQL.\n",
      "I have attended multiple #hackathons and presentations, including\n",
      "the #BFFHackathon, during which I contributed to developing a\n",
      "chatbot that provides mental health support and resources.\n",
      "As a #SoftwareEngineerTrainee at #JellyfishTechnologies, Noida,\n",
      "I am currently seeking a skill-driven organization that offers a\n",
      "competitive environment, unparalleled work culture, and lifelong\n",
      "memories to cherish.\n",
      "Experience\n",
      "Jellyfish Technologies \n",
      "1 year 8 months\n",
      "AI Engineer\n",
      "August 2024 - Present (1 year 2 months)\n",
      "Noida, Uttar Pradesh, India\n",
      "As an AI Engineer at Jellyfish Technologies, I specialize in developing and\n",
      "fine-tuning large language models (LLMs) to optimize AI-driven applications.\n",
      "My expertise includes instruction fine-tuning, domain adaptation, retrieval-\n",
      "augmented generation (RAG), and deploying AI models for real-world use\n",
      "cases.\n",
      "I work with a diverse technology stack, including Neo4j, MCP server, OCR,\n",
      "vector databases, FastAPI, and MongoDB, to build scalable and efficient AI\n",
      "  Page 1 of 2   \n",
      "systems. I also focus on data preparation, model evaluation, and pushing\n",
      "models/datasets to Hugging Face for seamless deployment and sharing.\n",
      "Beyond technical development, I collaborate closely with clients to understand\n",
      "their requirements, conduct research to identify the best AI solutions, and\n",
      "assist in pricing strategies. I help businesses integrate AI into their workflows\n",
      "by providing insights on feasibility, implementation, and optimization.\n",
      "Additionally, I play a key role in preparing high-quality datasets for model\n",
      "training, ensuring data integrity, and enhancing model performance. My work\n",
      "drives business innovation by leveraging cutting-edge AI/ML techniques\n",
      "to automate processes, improve decision-making, and enhance user\n",
      "experiences.\n",
      "Software engineer Trainee\n",
      "February 2024 - August 2024 (7 months)\n",
      "Noida, Uttar Pradesh, India\n",
      "Education\n",
      "St. Andrews Institute of Technology & Management\n",
      "Bachelor of Technology - BTech, Artificial intelligence and machine learning\n",
      " · (2020 - 2024)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8s558hlqvq",
   "metadata": {},
   "source": [
    "## Step 5: Profile Data Verification\n",
    "\n",
    "**Quality assurance check for extracted information**\n",
    "\n",
    "*Sometimes you need to see the raw data to make sure the PDF extraction didn't turn your professional summary into abstract poetry.*\n",
    "\n",
    "This step displays the complete extracted LinkedIn profile to verify:\n",
    "- **Text extraction accuracy** - ensuring no information was lost in translation\n",
    "- **Data completeness** - confirming all sections were captured\n",
    "- **Format preservation** - maintaining readable structure for AI processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152aae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/mynkchaudhry/Agenticai/assests/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aep5chto9b",
   "metadata": {},
   "source": [
    "## Step 6: Additional Context Integration\n",
    "\n",
    "**Loading supplementary information for enhanced representation**\n",
    "\n",
    "*Because sometimes a LinkedIn profile doesn't tell the whole story, and you need that extra context file to fill in the gaps.*\n",
    "\n",
    "This step loads additional summary information from an external text file to provide:\n",
    "- **Extended background details** not captured in the LinkedIn profile\n",
    "- **Personal insights and perspectives** for more authentic representation\n",
    "- **Supplementary context** to enhance the AI's understanding and response quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1faf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Mayank Chaudhary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irwil6xncl",
   "metadata": {},
   "source": [
    "## Step 7: Identity Configuration\n",
    "\n",
    "**Setting the stage for AI impersonation**\n",
    "\n",
    "*Simple but crucial - telling the AI exactly whose shoes it needs to fill. Getting this wrong would be like showing up to a job interview as the wrong person.*\n",
    "\n",
    "This variable establishes the primary identity that the AI assistant will represent throughout all interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90oyycia6k",
   "metadata": {},
   "source": [
    "## Step 8: System Prompt Engineering\n",
    "\n",
    "**Crafting the AI's personality and professional guidelines**\n",
    "\n",
    "*This is where we transform a generic chatbot into a sophisticated professional representative. Think of it as writing the ultimate job description for an AI employee.*\n",
    "\n",
    "The system prompt construction includes:\n",
    "\n",
    "**Core Instructions:**\n",
    "- **Identity establishment** - Clear role definition and representation guidelines\n",
    "- **Professional conduct** - Appropriate tone for client and employer interactions  \n",
    "- **Knowledge boundaries** - Honest acknowledgment of limitations\n",
    "- **Context integration** - Seamless incorporation of profile and summary data\n",
    "\n",
    "**Knowledge Base Integration:**\n",
    "- **Summary section** - Additional background context\n",
    "- **LinkedIn profile** - Complete professional history and skills\n",
    "- **Character consistency** - Maintaining authentic representation throughout conversations\n",
    "\n",
    "This comprehensive prompt ensures the AI maintains professional standards while accurately representing the individual's background and expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e84409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Mayank Chaudhary. You are answering questions on Mayank Chaudhary's website, particularly questions related to Mayank Chaudhary's career, background, skills and experience. Your responsibility is to represent Mayank Chaudhary for interactions on the website as faithfully as possible. You are given a summary of Mayank Chaudhary's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nContact\\nmayanktalan98@gmail.com\\nwww.linkedin.com/in/\\nmynkchaudhry (LinkedIn)\\nTop Skills\\nChatbots\\nKnowledge Engineering\\nRetrieval-Augmented Generation\\n(RAG)\\nCertifications\\nAI Agents Fundamentals\\nBFF Hackathon\\nGoogle Cloud\\nMayank Chaudhary\\nAI Engineer @jellyfishtechnologies\\nNoida, Uttar Pradesh, India\\nSummary\\nB.Tech student from St. Andrews Institute of Technology and\\nManagement, I am driven by an unwavering passion to learn\\nand innovate in the realms of #AI and #ML, encompassing\\n#DeepLearning, #ComputerVision, #Chatbots, #GenerativeAI, and\\nmachine learning algorithms.\\nThe #techstack I am well-versed with includes #LLMs, #RAG,\\n#HuggingFace, #Computervision, #NLP, #Python, and #SQL.\\nI have attended multiple #hackathons and presentations, including\\nthe #BFFHackathon, during which I contributed to developing a\\nchatbot that provides mental health support and resources.\\nAs a #SoftwareEngineerTrainee at #JellyfishTechnologies, Noida,\\nI am currently seeking a skill-driven organization that offers a\\ncompetitive environment, unparalleled work culture, and lifelong\\nmemories to cherish.\\nExperience\\nJellyfish Technologies \\n1 year 8 months\\nAI Engineer\\nAugust 2024 - Present (1 year 2 months)\\nNoida, Uttar Pradesh, India\\nAs an AI Engineer at Jellyfish Technologies, I specialize in developing and\\nfine-tuning large language models (LLMs) to optimize AI-driven applications.\\nMy expertise includes instruction fine-tuning, domain adaptation, retrieval-\\naugmented generation (RAG), and deploying AI models for real-world use\\ncases.\\nI work with a diverse technology stack, including Neo4j, MCP server, OCR,\\nvector databases, FastAPI, and MongoDB, to build scalable and efficient AI\\n  Page 1 of 2   \\nsystems. I also focus on data preparation, model evaluation, and pushing\\nmodels/datasets to Hugging Face for seamless deployment and sharing.\\nBeyond technical development, I collaborate closely with clients to understand\\ntheir requirements, conduct research to identify the best AI solutions, and\\nassist in pricing strategies. I help businesses integrate AI into their workflows\\nby providing insights on feasibility, implementation, and optimization.\\nAdditionally, I play a key role in preparing high-quality datasets for model\\ntraining, ensuring data integrity, and enhancing model performance. My work\\ndrives business innovation by leveraging cutting-edge AI/ML techniques\\nto automate processes, improve decision-making, and enhance user\\nexperiences.\\nSoftware engineer Trainee\\nFebruary 2024 - August 2024 (7 months)\\nNoida, Uttar Pradesh, India\\nEducation\\nSt. Andrews Institute of Technology & Management\\nBachelor of Technology - BTech, Artificial intelligence and machine learning\\n · (2020 - 2024)\\n  Page 2 of 2\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nmayanktalan98@gmail.com\\nwww.linkedin.com/in/\\nmynkchaudhry (LinkedIn)\\nTop Skills\\nChatbots\\nKnowledge Engineering\\nRetrieval-Augmented Generation\\n(RAG)\\nCertifications\\nAI Agents Fundamentals\\nBFF Hackathon\\nGoogle Cloud\\nMayank Chaudhary\\nAI Engineer @jellyfishtechnologies\\nNoida, Uttar Pradesh, India\\nSummary\\nB.Tech student from St. Andrews Institute of Technology and\\nManagement, I am driven by an unwavering passion to learn\\nand innovate in the realms of #AI and #ML, encompassing\\n#DeepLearning, #ComputerVision, #Chatbots, #GenerativeAI, and\\nmachine learning algorithms.\\nThe #techstack I am well-versed with includes #LLMs, #RAG,\\n#HuggingFace, #Computervision, #NLP, #Python, and #SQL.\\nI have attended multiple #hackathons and presentations, including\\nthe #BFFHackathon, during which I contributed to developing a\\nchatbot that provides mental health support and resources.\\nAs a #SoftwareEngineerTrainee at #JellyfishTechnologies, Noida,\\nI am currently seeking a skill-driven organization that offers a\\ncompetitive environment, unparalleled work culture, and lifelong\\nmemories to cherish.\\nExperience\\nJellyfish Technologies \\n1 year 8 months\\nAI Engineer\\nAugust 2024\\xa0-\\xa0Present\\xa0(1 year 2 months)\\nNoida, Uttar Pradesh, India\\nAs an AI Engineer at Jellyfish Technologies, I specialize in developing and\\nfine-tuning large language models (LLMs) to optimize AI-driven applications.\\nMy expertise includes instruction fine-tuning, domain adaptation, retrieval-\\naugmented generation (RAG), and deploying AI models for real-world use\\ncases.\\nI work with a diverse technology stack, including Neo4j, MCP server, OCR,\\nvector databases, FastAPI, and MongoDB, to build scalable and efficient AI\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nsystems. I also focus on data preparation, model evaluation, and pushing\\nmodels/datasets to Hugging Face for seamless deployment and sharing.\\nBeyond technical development, I collaborate closely with clients to understand\\ntheir requirements, conduct research to identify the best AI solutions, and\\nassist in pricing strategies. I help businesses integrate AI into their workflows\\nby providing insights on feasibility, implementation, and optimization.\\nAdditionally, I play a key role in preparing high-quality datasets for model\\ntraining, ensuring data integrity, and enhancing model performance. My work\\ndrives business innovation by leveraging cutting-edge AI/ML techniques\\nto automate processes, improve decision-making, and enhance user\\nexperiences.\\nSoftware engineer Trainee\\nFebruary 2024\\xa0-\\xa0August 2024\\xa0(7 months)\\nNoida, Uttar Pradesh, India\\nEducation\\nSt. Andrews Institute of Technology & Management\\nBachelor of Technology - BTech,\\xa0Artificial intelligence and machine learning\\n\\xa0·\\xa0(2020\\xa0-\\xa02024)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Mayank Chaudhary.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tudg33d20wh",
   "metadata": {},
   "source": [
    "## Step 9: System Prompt Inspection\n",
    "\n",
    "**Reviewing the AI's complete instruction set**\n",
    "\n",
    "*A final check to ensure our AI assistant has all the necessary information and instructions. Like proofreading a resume before submitting it to a dream job.*\n",
    "\n",
    "This output displays the complete system prompt including all integrated context, allowing for verification of:\n",
    "- **Instruction clarity and completeness**\n",
    "- **Proper context integration**  \n",
    "- **Professional tone and guidelines**\n",
    "- **Knowledge base accessibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-nano-2025-04-14\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mh0yo951rh",
   "metadata": {},
   "source": [
    "## Step 10: Core Chat Function Implementation\n",
    "\n",
    "**Building the conversational engine**\n",
    "\n",
    "*The heart of our AI assistant - where user messages transform into professional, contextually-aware responses. Like having a personal spokesperson who never has an off day.*\n",
    "\n",
    "**Function Architecture:**\n",
    "- **Message formatting** - Combines system prompt, conversation history, and user input\n",
    "- **Model selection** - Uses GPT-4.1 Nano for balanced performance and cost\n",
    "- **Response generation** - Leverages complete context for accurate representation\n",
    "- **Clean output** - Returns only the relevant response content\n",
    "\n",
    "This function serves as the primary interface between user queries and the AI's professional knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf91714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zmvm1wonx3",
   "metadata": {},
   "source": [
    "## Step 11: Launch Interactive Web Interface\n",
    "\n",
    "**Bringing the AI assistant to life with Gradio**\n",
    "\n",
    "*The moment of truth - transforming our sophisticated backend into a user-friendly web application. No HTML, CSS, or JavaScript required. Modern problems require modern solutions.*\n",
    "\n",
    "**Interface Features:**\n",
    "- **ChatInterface** - Pre-built conversational UI optimized for message-based interactions\n",
    "- **Message type handling** - Proper conversation flow and history management\n",
    "- **Local deployment** - Runs on localhost:7860 for development and testing\n",
    "- **Real-time interaction** - Immediate response generation and display\n",
    "\n",
    "The `type=\"messages\"` parameter ensures proper conversation context handling for multi-turn interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v72pkkgsesq",
   "metadata": {},
   "source": [
    "## Step 12: Evaluation Model Schema Definition\n",
    "\n",
    "**Structuring the quality assessment framework**\n",
    "\n",
    "*Using Pydantic to ensure our evaluation results are consistent and machine-readable. Because subjective feedback needs objective structure.*\n",
    "\n",
    "**Model Components:**\n",
    "- **is_acceptable** (boolean) - Clear pass/fail determination\n",
    "- **feedback** (string) - Detailed explanation of assessment reasoning\n",
    "\n",
    "This structured approach enables automated decision-making and continuous improvement of response quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ja3mvhu33m8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Advanced Quality Control System\n",
    "\n",
    "**Implementing AI-powered response evaluation and refinement**\n",
    "\n",
    "*Because even the best AI assistants sometimes need a second opinion. Think of this as having a professional editor review every response before publication.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2i3q2tqsr4d",
   "metadata": {},
   "source": [
    "## Step 13: Evaluator System Prompt Creation\n",
    "\n",
    "**Training the AI quality inspector**\n",
    "\n",
    "*Building a comprehensive instruction set for our AI evaluator. Think of this as creating the ultimate quality assurance manual for digital interactions.*\n",
    "\n",
    "**Evaluator Responsibilities:**\n",
    "- **Response quality assessment** - Determining professional appropriateness\n",
    "- **Context adherence** - Ensuring responses align with provided background\n",
    "- **Professional standard maintenance** - Verifying client/employer suitable tone\n",
    "- **Accuracy verification** - Confirming information consistency with source materials\n",
    "\n",
    "The evaluator receives complete context including summary and LinkedIn profile to make informed quality judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jwb0ffcoyv",
   "metadata": {},
   "source": [
    "## Step 14: Dynamic Evaluation Prompt Generator\n",
    "\n",
    "**Creating context-aware evaluation requests**\n",
    "\n",
    "*This function assembles all the pieces needed for thorough response evaluation. Like preparing a complete case file for the AI quality reviewer.*\n",
    "\n",
    "**Prompt Components:**\n",
    "- **Conversation history** - Full context of the interaction\n",
    "- **User's latest message** - The specific query being addressed\n",
    "- **AI's response** - The answer under evaluation\n",
    "- **Evaluation request** - Clear instructions for assessment criteria\n",
    "\n",
    "This comprehensive approach ensures the evaluator has complete context for making accurate quality determinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1466d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qm0ris9em6",
   "metadata": {},
   "source": [
    "## Step 15: Multi-Model Architecture Setup\n",
    "\n",
    "**Diversifying our AI evaluation capabilities**\n",
    "\n",
    "*Using Google's Gemini as our independent evaluator - because sometimes you need a second opinion from a different AI family tree.*\n",
    "\n",
    "This creates a separate client for Gemini 2.0 Flash, providing:\n",
    "- **Independent evaluation perspective** - Different model architecture for unbiased assessment\n",
    "- **Structured response parsing** - Built-in support for Pydantic model formatting\n",
    "- **Enhanced reliability** - Multiple AI systems for comprehensive quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mlccdo6dhjb",
   "metadata": {},
   "source": [
    "## Step 16: Core Evaluation Function\n",
    "\n",
    "**Implementing automated quality assessment**\n",
    "\n",
    "*The quality control engine that determines whether responses meet professional standards. Like having a digital proofreader with impeccable judgment.*\n",
    "\n",
    "**Function Process:**\n",
    "1. **Message composition** - Combines evaluator system prompt with evaluation request\n",
    "2. **Structured parsing** - Uses Gemini's beta parsing feature for consistent output format\n",
    "3. **Quality determination** - Returns structured evaluation with acceptance status and feedback\n",
    "4. **Format guarantee** - Ensures responses conform to Evaluation model schema\n",
    "\n",
    "This function serves as the gatekeeper for all AI-generated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45glswtc2e1",
   "metadata": {},
   "source": [
    "## Step 17: Quality Control Testing\n",
    "\n",
    "**Validating the evaluation system with a test case**\n",
    "\n",
    "*Time to put our quality control system through its paces. Let's see if our AI evaluator can spot the difference between good and questionable responses.*\n",
    "\n",
    "This test generates a response to a specific query about patents to demonstrate:\n",
    "- **Response generation process** - Standard AI assistant behavior\n",
    "- **Content appropriateness** - Professional and accurate information delivery\n",
    "- **Evaluation readiness** - Preparation for quality assessment testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968e190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, I do not hold any patents. My focus has primarily been on developing skills and gaining experience in AI and machine learning during my studies and work as an AI Engineer at Jellyfish Technologies. However, I am passionate about innovation and look forward to contributing to and potentially filing patents in the future as I grow in my career. If you have any further questions or inquiries, feel free to ask!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065gvd1mb6d2",
   "metadata": {},
   "source": [
    "## Step 18: Response Quality Inspection\n",
    "\n",
    "**Reviewing the AI's initial response**\n",
    "\n",
    "*Here's what our AI assistant came up with. Professional, honest, and appropriately detailed - exactly what you'd want from a digital representative.*\n",
    "\n",
    "This output demonstrates the AI's ability to provide accurate, professional responses while maintaining appropriate boundaries about unknown information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"This response is great. It's a clear and honest answer. It also sets the stage for future innovation and career growth, which is a good thing to include.\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kp63bxto5v",
   "metadata": {},
   "source": [
    "## Step 19: Evaluation System Validation\n",
    "\n",
    "**Testing the AI evaluator's judgment**\n",
    "\n",
    "*The moment of truth - will our AI evaluator approve of our AI assistant's response? Spoiler alert: good responses should pass with flying colors.*\n",
    "\n",
    "This test demonstrates the evaluation system's ability to assess response quality and provide structured feedback for quality control purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70786ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otwcxq0thg",
   "metadata": {},
   "source": [
    "## Step 20: Response Refinement System\n",
    "\n",
    "**Building the automatic improvement mechanism**\n",
    "\n",
    "*When the first attempt doesn't meet quality standards, this function gives the AI a chance to learn from its mistakes and try again. Like having a personal editor who never gets tired of revisions.*\n",
    "\n",
    "**Refinement Process:**\n",
    "1. **Feedback integration** - Incorporates evaluator's specific concerns into system prompt\n",
    "2. **Context preservation** - Maintains conversation history and user query\n",
    "3. **Guided improvement** - Uses rejection feedback to generate better responses\n",
    "4. **Second chance generation** - Produces refined output with enhanced quality focus\n",
    "\n",
    "This iterative approach ensures consistent professional quality in all interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w7mvfr7r1bs",
   "metadata": {},
   "source": [
    "## Step 21: Enhanced Chat Function with Quality Control\n",
    "\n",
    "**Integrating automatic evaluation and refinement**\n",
    "\n",
    "*The evolution of our chat function - now with built-in quality assurance that would make any QA team proud. This version includes conditional logic for testing edge cases.*\n",
    "\n",
    "**Advanced Features:**\n",
    "- **Conditional system prompt modification** - Demonstrates handling of specific scenarios (patent queries trigger pig latin mode for testing)\n",
    "- **Automatic evaluation** - Every response gets quality-checked before delivery\n",
    "- **Intelligent retry mechanism** - Failed evaluations trigger automatic refinement\n",
    "- **Comprehensive logging** - Status updates for transparency in the improvement process\n",
    "\n",
    "This implementation showcases a production-ready AI assistant with robust quality control mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf3268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z6fh3f09map",
   "metadata": {},
   "source": [
    "## Step 22: Production Deployment\n",
    "\n",
    "**Launching the quality-controlled AI assistant**\n",
    "\n",
    "*The grand finale - deploying our sophisticated AI assistant with full quality control capabilities. Now running on localhost:7861 for testing the enhanced system.*\n",
    "\n",
    "This final implementation includes:\n",
    "- **Complete quality assurance pipeline** - Automatic evaluation and refinement\n",
    "- **Professional response standards** - Consistent, accurate, and appropriate interactions  \n",
    "- **Robust error handling** - Graceful management of edge cases and quality failures\n",
    "- **Production-ready architecture** - Scalable design suitable for real-world deployment\n",
    "\n",
    "The system is now ready to represent professionals with confidence and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdda438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nheqelwkojd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Project Summary\n",
    "\n",
    "**Successfully implemented a comprehensive personal AI assistant system featuring:**\n",
    "\n",
    "### Core Components\n",
    "- **PDF knowledge extraction** for professional profile integration\n",
    "- **Dynamic system prompt engineering** for authentic representation\n",
    "- **Interactive web interface** using Gradio framework\n",
    "- **Multi-model AI architecture** leveraging GPT and Gemini capabilities\n",
    "\n",
    "### Quality Assurance Features  \n",
    "- **Automated response evaluation** using structured assessment criteria\n",
    "- **Intelligent refinement system** for continuous improvement\n",
    "- **Professional standards enforcement** maintaining appropriate tone and accuracy\n",
    "- **Comprehensive error handling** ensuring reliable operation\n",
    "\n",
    "### Technical Achievements\n",
    "- **Pydantic model integration** for structured data handling\n",
    "- **Multi-API coordination** across OpenAI and Google platforms\n",
    "- **Real-time quality control** with automatic retry mechanisms\n",
    "- **Production-ready deployment** suitable for professional environments\n",
    "\n",
    "*The result: An AI assistant that not only knows you professionally but maintains the standards you'd expect from your best human representative.*\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:** Deploy to production environment, integrate with professional website, and monitor performance metrics for continuous optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
